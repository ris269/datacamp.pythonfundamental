#Chapters
01. Using iterators in PythonLand
02. List comprehensions and generators
03. Bringing it all together!

#Keywords
- Iterables
- Iterators
- List comprehensions
- Generators

##01. Using iterators in PythonLand

### Iterators vs iterables?
- Special objects called iterables: lists, strings and range object, dictionaries, file connections
- Iterable definition: an object that has an associated iter method
- an iterable is an object that can return an iterator, while an iterator is an object that keeps state and produces the next value when you call next() on it

#### Exercises
#### Iterating over iterables (1)
# Create a list of strings: flash
flash = ['jay garrick', 'barry allen', 'wally west', 'bart allen']

# Print each list item in flash using a for loop
for person in flash :
    print(person)

# Create an iterator for flash: superhero
superhero = iter(flash)

# Print each item from the iterator
print(next(superhero))
print(next(superhero))
print(next(superhero))
print(next(superhero))

#### Iterating over iterable (2)
# Create an iterator for range(3): small_value
small_value = iter(range(3))

# Print the values in small_value
print(next(small_value))
print(next(small_value))
print(next(small_value))

# Loop over range(3) and print the values
for num in range(3) :
    print(num)

# Create an iterator for range(10 ** 100): googol
googol = iter(range(10**100))

# Print the first 5 values from googol
print(next(googol))
print(next(googol))
print(next(googol))
print(next(googol))
print(next(googol))

#### Iterators as function arguments
# Create a range object: values
values = range(10, 21)

# Print the range object
print(values)

# Create a list of integers: values_list
values_list = list(values)

# Print values_list
print(values_list)

# Get the sum of values: values_sum
values_sum = sum(values)

# Print values_sum
print(values_sum)

#### Playing with iterators
#### Using enumerate
# Create a list of strings: mutants
mutants = ['charles xavier', 
            'bobby drake', 
            'kurt wagner', 
            'max eisenhardt', 
            'kitty pryde']

# Create a list of tuples: mutant_list
mutant_list = list(enumerate(mutants))

# Print the list of tuples
print(mutant_list)

# Unpack and print the tuple pairs
for index1, value1 in enumerate(mutants):
    print(index1, value1)

# Change the start index
for index2, value2 in enumerate(mutants, start=1):
    print(index2, value2)

#### Using zip
# Create a list of tuples: mutant_data
mutant_data = list(zip(mutants, aliases, powers))

# Print the list of tuples
print(mutant_data)

# Create a zip object using the three lists: mutant_zip
mutant_zip = zip(mutants, aliases, powers)

# Print the zip object
print(mutant_zip)

# Unpack the zip object and print the tuple values
for value1, value2, value3 in mutant_zip :
    print(value1, value2, value3)

#### Using * and zip to 'unzip'
# Create a zip object from mutants and powers: z1
z1 = zip(mutants, powers)

# Print the tuples in z1 by unpacking with *
print(*z1)

# Re-create a zip object from mutants and powers: z1
z1 = zip(mutants, powers)

# 'Unzip' the tuples in z1 by unpacking with * and zip(): result1, result2
result1, result2 = zip(*z1) 

# Check if unpacked tuples are equivalent to original tuples
print(result1 == mutants)
print(result2 == powers)

#### Using iterators to load large files into memory

#### Processing large amounts of Twitter data
# Initialize an empty dictionary: counts_dict
counts_dict = {}

# Iterate over the file chunk by chunk
for chunk in pd.read_csv('tweets.csv', chunksize=10):

    # Iterate over the column in DataFrame
    for entry in chunk['lang']:
        if entry in counts_dict.keys():
            counts_dict[entry] += 1
        else:
            counts_dict[entry] = 1

# Print the populated dictionary
print(counts_dict)

#### Extracting information for large amounts of Twitter data
# Define count_entries()
def count_entries(csv_file, c_size, colname):
    """Return a dictionary with counts of
    occurrences as value for each key."""
    
    # Initialize an empty dictionary: counts_dict
    counts_dict = {}

    # Iterate over the file chunk by chunk
    for chunk in pd.read_csv(csv_file, chunksize=c_size):

        # Iterate over the column in DataFrame
        for entry in chunk[colname]:
            if entry in counts_dict.keys():
                counts_dict[entry] += 1
            else:
                counts_dict[entry] = 1

    # Return counts_dict
    return counts_dict

# Call count_entries(): result_counts
result_counts = count_entries('tweets.csv', 10, 'lang')

# Print result_counts
print(result_counts)


##02. List comprehensions and generators

[[output expression] for iterator variable in iterable]

[ output expression for iterator variable in iterable if predicate expression ].


#### Write a basic list comprehension

#### List comprehension over iterables

#### Writing list comprehension
# Create list comprehension: squares
squares = [i ** 2 for i in range(0, 10)]

#### Nested list comprehensions
# Create a 5 x 5 matrix using a list of lists: matrix
matrix = [[col for col in range(0,5)] for row in range(0,5)]

# Print the matrix
for row in matrix:
    print(row)

#### Using conditionals in comprehension (1)
# Create a list of strings: fellowship
fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']

# Create list comprehension: new_fellowship
new_fellowship = [member for member in fellowship if len(member) >= 7]

# Print the new list
print(new_fellowship)

#### Using conditionals in comprehension (2)
# Create a list of strings: fellowship
fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']

# Create list comprehension: new_fellowship
new_fellowship = [member if len(member) >= 7 else '' for member in fellowship]

# Print the new list
print(new_fellowship)

#### Dict comprehensions
# Create a list of strings: fellowship
fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']

# Create dict comprehension: new_fellowship
new_fellowship = {member : len(member) for member in fellowship}

# Print the new dictionary
print(new_fellowship)

### Introduction to generator expression
#A generator is like a list comprehension except it does not store the list in the memory
#It does not construct the list but is an object we can iterate over to produce elements of the list as required

#### List comprehensions vs generators
# List of strings
fellowship = ['frodo', 'samwise', 'merry', 'aragorn', 'legolas', 'boromir', 'gimli']
#output:
# List comprehension
fellow1 = [member for member in fellowship if len(member) >= 7]
#output:['samwise', 'aragorn', 'legolas', 'boromir']
# Generator expression
fellow2 = (member for member in fellowship if len(member) >= 7)
#output: <generator object <genexpr> at 0x7f97d0736990>
#CONCLUSION: A list comprehension produces a list as output, a generator produces a generator object.

#### Write your own generator expressions
# Create generator object: result
result = (num for num in range(0,31))

# Print the first 5 values
print(next(result))
print(next(result))
print(next(result))
print(next(result))
print(next(result))

# Print the rest of the values
print('VALUE')
for value in result:
    print(value)

#### Changing the output in generator expressions
# Create a list of strings: lannister
lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']

# Create a generator object: lengths
lengths = (len(person) for person in lannister)

# Iterate over and print the values in lengths
for value in lengths:
    print(value)

#### Build a generator
# Create a list of strings
lannister = ['cersei', 'jaime', 'tywin', 'tyrion', 'joffrey']

# Define generator function get_lengths
def get_lengths(input_list):
    """Generator function that yields the
    length of the strings in input_list."""

    # Yield the length of a string
    for person in input_list:
        yield len(person)

# Print the values generated by get_lengths()
for value in get_lengths(lannister):
    print(value)

#### Wrapping up comprehensions and generators

#### List comprehensions for time-stamped data
# Extract the created_at column from df: tweet_time
tweet_time = df.created_at

# Extract the clock time: tweet_clock_time
tweet_clock_time = [entry[11:19] for entry in tweet_time]

# # Print the extracted times
print(tweet_clock_time)

#### Conditional list comprehensions for time-stamped data
# Extract the created_at column from df: tweet_time
tweet_time = df.created_at

# Extract the clock time: tweet_clock_time
tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']

# Print the extracted times
print(tweet_clock_time)


##03. Bring it all together!

### Case study

#### Dictionaries for data science
# Zip lists: zipped_lists
zipped_lists = zip(feature_names, row_vals)

# Create a dictionary: rs_dict
rs_dict = dict(zipped_lists)

# Print the dictionary
print(rs_dict)

#### Writing a function to help you
# Define lists2dict()
def lists2dict(list1, list2):
    """Return a dictionary where list1 provides
    the keys and list2 provides the values."""

    # Zip lists: zipped_lists
    zipped_lists = zip(list1, list2)

    # Create a dictionary: rs_dict
    rs_dict = dict(zipped_lists)

    # Return the dictionary
    return rs_dict

# Call lists2dict: rs_fxn
rs_fxn = lists2dict(feature_names, row_vals)

# Print rs_fxn
print(rs_fxn)

#### Using a list comprehension

# Print the first two lists in row_lists
print(row_lists[0])
print(row_lists[1])

# Turn list of lists into list of dicts: list_of_dicts
list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]

# Print the first two dictionaries in list_of_dicts
print(list_of_dicts[0])
print(list_of_dicts[1])

#### Turning this all into a DataFrame
# Import the pandas package
import pandas as pd

# Turn list of lists into list of dicts: list_of_dicts
list_of_dicts = [lists2dict(feature_names, sublist) for sublist in row_lists]

# Turn list of dicts into a DataFrame: df
df = pd.DataFrame(list_of_dicts)

# Print the head of the DataFrame
print(df.head())

### Using Python generators for streaming data
# Open a connection to the file
with open('world_dev_ind.csv') as file:

    # Skip the column names
    file.readline()

    # Initialize an empty dictionary: counts_dict
    counts_dict = {}

    # Process only the first 1000 rows
    for j in range(1000):

        # Split the current line into a list: line
        line = file.readline().split(',')

        # Get the value for the first column: first_col
        first_col = line[0]

        # If the column value is in the dict, increment its value
        if first_col in counts_dict.keys():
            counts_dict[first_col] += 1

        # Else, add to the dict and set value to 1
        else:
            counts_dict[first_col] = 1

# Print the resulting dictionary
print(counts_dict)

#### Writing a generator to load data in chunks (2)
# Define read_large_file()
def read_large_file(file_object):
    """A generator function to read a large file lazily."""

    # Loop indefinitely until the end of the file
    while True:

        # Read a line from the file: data
        data = file_object.readline()

        # Break if this is the end of the file
        if not data:
            break

        # Yield the line of data
        yield data
        
# Open a connection to the file
with open('world_dev_ind.csv') as file:

    # Create a generator object for the file: gen_file
    gen_file = read_large_file(file)

    # Print the first three lines of the file
    print(next(gen_file))
    print(next(gen_file))
    print(next(gen_file))

#### Writing a generator to load data in chunks (3)
# Initialize an empty dictionary: counts_dict
counts_dict = {}

# Open a connection to the file
with open('world_dev_ind.csv') as file:

    # Iterate over the generator from read_large_file()
    for line in read_large_file(file):

        row = line.split(',')
        first_col = row[0]

        if first_col in counts_dict.keys():
            counts_dict[first_col] += 1
        else:
            counts_dict[first_col] = 1

# Print            
print(counts_dict)

### Using pandas' read_csv iterator for streaming data
#### Writing an iterator to load data in chunks (1)
'''
Writing an iterator to load data in chunks (1)
100xp
Another way to read data too large to store in memory in chunks is to read the file in as
DataFrames of a certain length, say, 100. For example, with the pandas package (imported as pd),
you can do pd.read_csv(filename, chunksize=100). This creates an iterable reader object, which
means that you can use next() on it.
In this exercise, you will read a file in small DataFrame chunks with read_csv(). You're going
to use the World Bank Indicators data 'ind_pop.csv', available in your current directory, to look
at the urban population indicator for numerous countries and years.
Instructions
-Use pd.read_csv() to read in 'ind_pop.csv' in chunks of size 10. Assign the result to df_reader.
-Print the first two chunks from df_reader.
'''

# Import the pandas package
import pandas as pd

# Initialize reader object: df_reader
df_reader = pd.read_csv('ind_pop.csv', chunksize=10)

# Print two chunks
print(next(df_reader))
print(next(df_reader))

#### Writing an iterator to load data in chunks (2)

'''
Writing an iterator to load data in chunks (2)
100xp
In the previous exercise, you used read_csv() to read in DataFrame chunks from a large dataset.
In this exercise, you will read in a file using a bigger DataFrame chunk size and then process
the data from the first chunk.
To process the data, you will create another DataFrame composed of only the rows from a specific
country. You will then zip together two of the columns from the new DataFrame, 'Total Population' 
and 'Urban population (% of total)'. Finally, you will create a list of tuples from the zip object,
where each tuple is composed of a value from each of the two columns mentioned.
You're going to use the data from 'ind_pop_data.csv', available in your current directory. Pandas
has been imported as pd.
Instructions
-Use pd.read_csv() to read in the file in 'ind_pop_data.csv' in chunks of size 1000. Assign the
result to urb_pop_reader.
-Get the first DataFrame chunk from the iterable urb_pop_reader and assign this to df_urb_pop.
-Select only the rows of df_urb_pop that have a 'CountryCode' of 'CEB'. To do this, compare whether
df_urb_pop['CountryCode'] is equal to 'CEB' within the square brackets in df_urb_pop[____].
-Using zip(), zip together the 'Total Population' and 'Urban population (% of total)' columns of
df_pop_ceb. Assign the resulting zip object to pops.
'''
# Initialize reader object: urb_pop_reader
urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)

# Get the first DataFrame chunk: df_urb_pop
df_urb_pop = next(urb_pop_reader)

# Check out the head of the DataFrame
print(df_urb_pop.head())

# Check out specific country: df_pop_ceb
df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']

# Zip DataFrame columns of interest: pops
pops = zip(df_pop_ceb['Total Population'], 
            df_pop_ceb['Urban population (% of total)'])

# Turn zip object into list: pops_list
pops_list = list(pops)

# Print pops_list
print(pops_list)

#### Writing an iterator to load data in chunks (3)
'''
Writing an iterator to load data in chunks (3)

You're getting used to reading and processing data in chunks by now. Let's push your skills a
little further by adding a column to a DataFrame.
In this exercise, you will be using a list comprehension to create the values for a new column
'Total Urban Population' from the list of tuples that you generated earlier. Recall from the
previous exercise that the first and second elements of each tuple consist of, respectively,
values from the columns 'Total Population' and 'Urban population (% of total)'. The values in
this new column 'Total Urban Population', therefore, are the product of the first and second
element in each tuple. Furthermore, because the 2nd element is a percentage, you need to divide
the entire result by 100, or alternatively, multiply it by 0.01.
You will also plot the data from this new column to create a visualization of the urban
population data.
You're going to use the data from 'ind_pop_data.csv', available in your current directory.
The packages pandas and matplotlib.pyplot have been imported as pd and plt respectively for your use.
Instructions
-Use pd.read_csv() to read in the file 'ind_pop_data.csv' in chunks of size 1000. Assign the
result to urb_pop_reader.
-Write a list comprehension to generate a list of values from pops_list for the new column
'Total Urban Population'. Use tup as the iterator variable. The output expression should be the
product of the first and second element in each tuple in pops_list. Because the 2nd element is a
percentage, you also need to either multiply the result by 0.01 or divide it by 100. In addition,
note that the column 'Total Urban Population' should only be able to take on integer values.
To ensure this, make sure you cast the output expression to an integer with int().
-Create a scatter plot where the x-axis are values from the 'Year' column and the y-axis are values
from the 'Total Urban Population' column.
'''
# Initialize reader object: urb_pop_reader
urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)

# Get the first DataFrame chunk: df_urb_pop
df_urb_pop = next(urb_pop_reader)

# Check out specific country: df_pop_ceb
df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']

# Zip DataFrame columns of interest: pops
pops = zip(df_pop_ceb['Total Population'], 
            df_pop_ceb['Urban population (% of total)'])

# Turn zip object into list: pops_list
pops_list = list(pops)

# Use list comprehension to create new DataFrame column 'Total Urban Population'
df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1] * 0.01) for tup in pops_list]

# Plot urban population data
df_pop_ceb.plot(kind='scatter', x='Year', y='Total Urban Population')
plt.show()

#### Writing an iterator to load data in chunks (4)
'''
Writing an iterator to load data in chunks (4)
100xp
In the previous exercises, you've only processed the data from the first DataFrame chunk.
This time, you will aggregate the results over all the DataFrame chunks in the dataset. 
This basically means you will be processing the entire dataset now. This is neat because
you're going to be able to process the entire large dataset by just working on smaller pieces of it!
You're going to use the data from 'ind_pop_data.csv', available in your current directory.
The packages pandas and matplotlib.pyplot have been imported as pd and plt respectively for your use.
Instructions
-Initialize an empty DataFrame data using pd.DataFrame().
-In the for loop, iterate over urb_pop_reader to be able to process all the DataFrame chunks
in the dataset.
-Using append() on data, append df_pop_ceb to data.
'''

# Initialize reader object: urb_pop_reader
urb_pop_reader = pd.read_csv('ind_pop_data.csv', chunksize=1000)

# Initialize empty DataFrame: data
data = pd.DataFrame()

# Iterate over each DataFrame chunk
for df_urb_pop in urb_pop_reader:

    # Check out specific country: df_pop_ceb
    df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == 'CEB']

    # Zip DataFrame columns of interest: pops
    pops = zip(df_pop_ceb['Total Population'],
                df_pop_ceb['Urban population (% of total)'])

    # Turn zip object into list: pops_list
    pops_list = list(pops)

    # Use list comprehension to create new DataFrame column 'Total Urban Population'
    df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1]) for tup in pops_list]
    
    # Append DataFrame chunk to data: data
    data = data.append(df_pop_ceb)

# Plot urban population data
data.plot(kind='scatter', x='Year', y='Total Urban Population')
plt.show()

#### Writing an iterator to load data in chunks (5)
  
'''
Writing an iterator to load data in chunks (5)
100xp
This is the last leg. You've learned a lot about processing a large dataset in chunks. In
this last exercise, you will put all the code for processing the data into a single function
so that you can reuse the code without having to rewrite the same things all over again.
You're going to define the function plot_pop() which takes two arguments: the filename of the
file to be processed, and the country code of the rows you want to process in the dataset.
Because all of the previous code you've written in the previous exercises will be housed in
plot_pop(), calling the function already does the following:
-Loading of the file chunk by chunk,
-Creating the new column of urban population values, and
-Plotting the urban population data.
That's a lot of work, but the function now makes it convenient to repeat the same process for
whatever file and country code you want to process and visualize!
You're going to use the data from 'ind_pop_data.csv', available in your current directory. The
packages pandas and matplotlib.pyplot has been imported as pd and plt respectively for your use.
After you are done, take a moment to look at the plots and reflect on the new skills you have acquired.
The journey doesn't end here! If you have enjoyed working with this data, you can continue exploring
it using the pre-processed version available on Kaggle.
Instructions
-Define the function plot_pop() that has two arguments: first is filename for the file to 
process and second is country_code for the country to be processed in the dataset.
-Call plot_pop() to process the data for country code 'CEB' in the file 'ind_pop_data.csv'.
-Call plot_pop() to process the data for country code 'ARB' in the file 'ind_pop_data.csv'.
'''
# Define plot_pop()
def plot_pop(filename, country_code):

    # Initialize reader object: urb_pop_reader
    urb_pop_reader = pd.read_csv(filename, chunksize=1000)

    # Initialize empty DataFrame: data
    data = pd.DataFrame()
    
    # Iterate over each DataFrame chunk
    for df_urb_pop in urb_pop_reader:
        # Check out specific country: df_pop_ceb
        df_pop_ceb = df_urb_pop[df_urb_pop['CountryCode'] == country_code]

        # Zip DataFrame columns of interest: pops
        pops = zip(df_pop_ceb['Total Population'],
                    df_pop_ceb['Urban population (% of total)'])

        # Turn zip object into list: pops_list
        pops_list = list(pops)

        # Use list comprehension to create new DataFrame column 'Total Urban Population'
        df_pop_ceb['Total Urban Population'] = [int(tup[0] * tup[1]) for tup in pops_list]
    
        # Append DataFrame chunk to data: data
        data = data.append(df_pop_ceb)

    # Plot urban population data
    data.plot(kind='scatter', x='Year', y='Total Urban Population')
    plt.show()

# Set the filename: fn
fn = 'ind_pop_data.csv'

# Call plot_pop for country code 'CEB'
plot_pop(fn, 'CEB')

# Call plot_pop for country code 'ARB'
plot_pop(fn, 'ARB')


